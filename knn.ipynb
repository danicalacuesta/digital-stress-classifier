#CS 513: Knowledge Discovery and Data 
#Group Members: Danica Lacuesta, Joelle An, and Raj Rana 
#Author: Joelle An
#20015285
#I pledge my honor that I have abided by the Stevens Honor System
#Purpose: This project analyzes digital activity patterns to classify user stress levels and identify the behavioral features that most strongly impact predictive accuracy.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns

# Import dataset
df = pd.read_csv("/data/df_modified.csv")

# drop unnamed index columns
df.drop(df.columns[df.columns.str.contains("unnamed", case=False)], axis=1, inplace=True)

# drop rows with nulls
df.dropna(inplace=True)

df.head()


# assume last column is the target
target_col = df.columns[-1]

y = df[target_col]
X = df.drop(target_col, axis=1)

# convert categorical text to one-hot encoding
categorical_cols = X.select_dtypes(include=["object", "category"]).columns.tolist()
numeric_cols = X.select_dtypes(include=["int64", "float64"]).columns.tolist()

X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)


non_scaled_features = [col for col in X.columns if col not in numeric_cols]

preprocessor = ColumnTransformer(
    transformers=[
        ("num", MinMaxScaler(), numeric_cols),
        ("pass", "passthrough", non_scaled_features),
    ]
)

X_processed = preprocessor.fit_transform(X)

# rebuild dataframe so later code works the same
final_features = numeric_cols + non_scaled_features
X_processed = pd.DataFrame(X_processed, columns=final_features)


attr_train, attr_test, target_train, target_test = train_test_split(
    X_processed, y, test_size=0.30, random_state=42
)

k_values = [20]
test_accuracies = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')
    knn.fit(attr_train, target_train)
    target_pred = knn.predict(attr_test)

    accuracy = accuracy_score(target_test, target_pred)
    test_accuracies.append(accuracy)

    print(f"Accuracy with k={k}: {accuracy}")
    scores = cross_val_score(knn, attr_train, target_train, cv=5)
    print("Cross-validated Score:", scores.mean(), "\n")


accuracy = accuracy_score(target_test, target_pred)
conf_matrix = confusion_matrix(target_test, target_pred)
class_report = classification_report(target_test, target_pred)

print(f"Accuracy: {accuracy:.4f}")
print("\nConfusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", class_report)

test_actual = attr_test.copy()
test_actual["pred"] = target_pred
test_actual["actual"] = target_test

misclassified = (test_actual["pred"] != test_actual["actual"]).sum()
error_rate = misclassified / len(test_actual)

print(f"Error rate: {error_rate:.2%}")



plt.figure(figsize=(6, 4))
ax = plt.subplot()
sns.heatmap(conf_matrix, annot=True, fmt="g", cmap="Blues", ax=ax)

ax.set_xlabel("Predicted")
ax.set_ylabel("Actual")
ax.set_title("KNN Confusion Matrix")

plt.show()


false_positives = test_actual[(test_actual["pred"] == 1) & (test_actual["actual"] == 0)]
false_negatives = test_actual[(test_actual["pred"] == 0) & (test_actual["actual"] == 1)]

false_positives.head(), false_negatives.head()
